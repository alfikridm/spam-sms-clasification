{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t2\n",
      "(1, 8)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1 1 1 1 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "text = ['The quick brown fox jumped over the lazy dog']\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(text)\n",
    "print(vectorizer.vocabulary_)\n",
    "vector = vectorizer.transform(text)\n",
    "print(vector)\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-39485f322708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datasets\\singlish.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"msg\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# reorder index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;31m###########################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\chunk\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChunkParserI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m from nltk.chunk.util import (\n\u001b[0;32m    159\u001b[0m     \u001b[0mChunkScore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\chunk\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m##//////////////////////////////////////////////////////\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParserI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChunkScore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\parse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmalt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaltParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDependencyEvaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransitionparser\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTransitionParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbllip\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBllipParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorenlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCoreNLPParser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCoreNLPDependencyParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\parse\\transitionparser.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m _DEFAULT_TAGS = {\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\_joblib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# joblib imports may raise DeprecationWarning on certain Python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnumpy_pickle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcompressor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_compressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_multiprocessing_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mformat_stack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mformat_outer_frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_multiprocessing_helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spawn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mSemaphore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSemaphore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0m_sem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSemaphore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0m_sem\u001b[0m  \u001b[1;31m# cleanup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36mSemaphore\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mSemaphore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;34m'''Returns a semaphore object'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSemaphore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSemaphore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\synchronize.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Try to import the mp.synchronize module cleanly, if it fails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mForkAwareThreadLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\util.py\u001b[0m in \u001b[0;36mForkAwareThreadLock\u001b[1;34m()\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mForkAwareThreadLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mregister_after_fork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForkAwareThreadLock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import sys\n",
    "df = pd.read_csv('datasets\\singlish.txt', sep=\"\\t\", header=None, names = [\"class\", \"msg\"])\n",
    "df = df[['msg', 'class']] # reorder index\n",
    "df['class'] = df['class'].replace(['ham'], '0').replace(['spam'], '1') # represents class using number\n",
    "df.language = 'english'\n",
    "df.stop_words = nltk.corpus.stopwords.words(df.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3a\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('datasets\\indo.csv')\n",
    "df2.columns = ['msg', 'class'] #rename\n",
    "df2['class'] = df['class'].replace([1,2], '1') # promo & fraud = spam (1)\n",
    "df2.language = 'indonesian'\n",
    "df2.stop_words = nltk.corpus.stopwords.words(df.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 msg class\n",
       "0  Go until jurong point, crazy.. Available only ...     0\n",
       "1                      Ok lar... Joking wif u oni...     0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3  U dun say so early hor... U c already then say...     0\n",
       "4  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PROMO] Beli paket Flash mulai 1GB di MY TELKO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 msg class\n",
       "0  [PROMO] Beli paket Flash mulai 1GB di MY TELKO...     0\n",
       "1  2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...     0\n",
       "2  2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...     1\n",
       "3  2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...     0\n",
       "4  4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preproccs DF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        msg\n",
       "class      \n",
       "0      4825\n",
       "1       747"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "spam_count = df.groupby('class').count()\n",
    "spam_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of Spam Texts')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(spam_count.index.values, spam_count['msg'])\n",
    "plt.xlabel('Spam Label')\n",
    "plt.ylabel('Number of Spam Texts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_table = df.msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_table = text_table.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in set(stop_words))\n",
    ")\n",
    "text_table = text_table.str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b',\n",
    "                                   'emailaddr')\n",
    "text_table = text_table.str.replace(r'(https[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\s*)',\n",
    "                                   'httpaddr')\n",
    "text_table = text_table.str.replace(\n",
    "    r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "    'phonenumbr')\n",
    "text_table = text_table.str.replace(r'\\d+(\\.\\d+)?','numbr')\n",
    "text_table = text_table.str.lower()\n",
    "text_table = text_table.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "text_table = text_table.str.replace(r'\\s+',' ')\n",
    "text_table = text_table.str.replace(r'^\\s+|\\s+?$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "lem = nltk.WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.msg = text_table.apply(lambda x: ' '.join(\n",
    "   lem.lemmatize(term) for term in x.split())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "df.msg = text_table.apply(lambda x: ' '.join(\n",
    "    porter.stem(term) for term in x.split())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    go jurong point crazi avail bugi n great world...\n",
       "1                                ok lar joke wif u oni\n",
       "2    free entri numbr wkli comp win fa cup final tk...\n",
       "3                  u dun say earli hor u c alreadi say\n",
       "4               nah i think goe usf live around though\n",
       "Name: msg, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x7838 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45205 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range=(1,1),tokenizer=token.tokenize)\n",
    "text1=cv.fit_transform(text_table)\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "text_table2 = text_table.apply(lambda x: ' '.join(\n",
    "    porter.stem(term) for term in x.split())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x6541 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45471 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2=cv.fit_transform(text_table2)\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=' '.join(df.msg)\n",
    "str_list = s.lower().split()\n",
    "unique_words = set(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictwords = dict()\n",
    "for words in unique_words:\n",
    "    dictwords[words] = [str_list.count(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entri numbr wkli comp win fa cup final tk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah i think goe usf live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 msg class\n",
       "0  go jurong point crazi avail bugi n great world...     0\n",
       "1                              ok lar joke wif u oni     0\n",
       "2  free entri numbr wkli comp win fa cup final tk...     1\n",
       "3                u dun say earli hor u c alreadi say     0\n",
       "4             nah i think goe usf live around though     0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataham = df[df['class'] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataspam = df[df['class'] == '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sham = ' '.join(dataham.msg)\n",
    "sspam = ' '.join(dataspam.msg)\n",
    "sham_list = sham.lower().split()\n",
    "sspam_list = sspam.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in unique_words :\n",
    "    iham=sham_list.count(words)\n",
    "    ispam=sspam_list.count(words)\n",
    "    dictwords[words].append(iham)\n",
    "    dictwords[words].append(ispam)\n",
    "    dictwords[words].append(ispam-iham)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortfreq = sorted(dictwords.items(), key=lambda x: x[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numbr', [2479, 884, 1595, 711]),\n",
       " ('i', [2243, 2188, 55, -2133]),\n",
       " ('u', [1198, 1024, 174, -850]),\n",
       " ('call', [667, 291, 376, 85]),\n",
       " ('you', [548, 417, 131, -286]),\n",
       " ('s', [505, 418, 87, -331]),\n",
       " ('go', [455, 420, 35, -385]),\n",
       " ('get', [444, 354, 90, -264]),\n",
       " ('m', [427, 403, 24, -379]),\n",
       " ('phonenumbr', [408, 1, 407, 406]),\n",
       " ('it', [390, 378, 12, -366]),\n",
       " ('ur', [390, 246, 144, -102]),\n",
       " ('gt', [318, 318, 0, -318]),\n",
       " ('lt', [316, 316, 0, -316]),\n",
       " ('now', [305, 170, 135, -35]),\n",
       " ('come', [302, 297, 5, -292]),\n",
       " ('free', [282, 59, 223, 164]),\n",
       " ('ok', [282, 277, 5, -272]),\n",
       " ('know', [273, 247, 26, -221]),\n",
       " ('day', [272, 240, 32, -208]),\n",
       " ('like', [259, 246, 13, -233]),\n",
       " ('love', [259, 249, 10, -239]),\n",
       " ('time', [249, 230, 19, -211]),\n",
       " ('want', [247, 214, 33, -181]),\n",
       " ('no', [245, 191, 54, -137]),\n",
       " ('me', [243, 233, 10, -223]),\n",
       " ('t', [240, 159, 81, -78]),\n",
       " ('good', [240, 228, 12, -216]),\n",
       " ('got', [238, 231, 7, -224]),\n",
       " ('text', [229, 86, 143, 57]),\n",
       " ('ll', [227, 224, 3, -221]),\n",
       " ('how', [212, 207, 5, -202]),\n",
       " ('send', [208, 135, 73, -62]),\n",
       " ('that', [203, 200, 3, -197]),\n",
       " ('do', [189, 175, 14, -161]),\n",
       " ('txt', [186, 14, 172, 158]),\n",
       " ('one', [185, 175, 10, -165]),\n",
       " ('need', [185, 174, 11, -163]),\n",
       " ('we', [184, 145, 39, -106]),\n",
       " ('today', [178, 140, 38, -102]),\n",
       " ('Ã¼', [172, 172, 0, -172]),\n",
       " ('see', [168, 149, 19, -130]),\n",
       " ('stop', [168, 45, 123, 78]),\n",
       " ('take', [167, 148, 19, -129]),\n",
       " ('can', [166, 161, 5, -156]),\n",
       " ('think', [165, 151, 14, -137]),\n",
       " ('what', [164, 157, 7, -150]),\n",
       " ('repli', [162, 50, 112, 62]),\n",
       " ('lor', [162, 162, 0, -162]),\n",
       " ('home', [162, 160, 2, -158]),\n",
       " ('so', [161, 157, 4, -153]),\n",
       " ('r', [161, 131, 30, -101]),\n",
       " ('sorri', [160, 157, 3, -154]),\n",
       " ('but', [160, 160, 0, -160]),\n",
       " ('still', [156, 149, 7, -142]),\n",
       " ('tell', [155, 137, 18, -119]),\n",
       " ('n', [154, 143, 11, -132]),\n",
       " ('back', [153, 130, 23, -107]),\n",
       " ('mobil', [152, 14, 138, 124]),\n",
       " ('numbrp', [151, 1, 150, 149]),\n",
       " ('da', [151, 151, 0, -151]),\n",
       " ('hi', [151, 133, 18, -115]),\n",
       " ('if', [151, 136, 15, -121]),\n",
       " ('make', [147, 134, 13, -121]),\n",
       " ('dont', [145, 133, 12, -121]),\n",
       " ('phone', [141, 84, 57, -27]),\n",
       " ('week', [141, 72, 69, -3]),\n",
       " ('say', [140, 139, 1, -138]),\n",
       " ('k', [139, 137, 2, -135]),\n",
       " ('just', [137, 106, 31, -75]),\n",
       " ('pleas', [137, 80, 57, -23]),\n",
       " ('work', [136, 133, 3, -130]),\n",
       " ('new', [136, 67, 69, 2]),\n",
       " ('later', [135, 135, 0, -135]),\n",
       " ('your', [134, 49, 85, 36]),\n",
       " ('my', [134, 131, 3, -128]),\n",
       " ('ask', [133, 127, 6, -121]),\n",
       " ('miss', [132, 122, 10, -112]),\n",
       " ('the', [131, 103, 28, -75]),\n",
       " ('hope', [131, 127, 4, -123]),\n",
       " ('pl', [128, 117, 11, -106]),\n",
       " ('meet', [126, 118, 8, -110]),\n",
       " ('msg', [124, 65, 59, -6]),\n",
       " ('night', [123, 116, 7, -109]),\n",
       " ('messag', [123, 74, 49, -25]),\n",
       " ('happi', [121, 120, 1, -119]),\n",
       " ('and', [121, 118, 3, -115]),\n",
       " ('wait', [120, 101, 19, -82]),\n",
       " ('dear', [119, 103, 16, -87]),\n",
       " ('c', [119, 64, 55, -9]),\n",
       " ('thi', [119, 77, 42, -35]),\n",
       " ('well', [118, 113, 5, -108]),\n",
       " ('tri', [117, 78, 39, -39]),\n",
       " ('much', [116, 115, 1, -114]),\n",
       " ('oh', [115, 114, 1, -113]),\n",
       " ('min', [115, 36, 79, 43]),\n",
       " ('thing', [115, 112, 3, -109]),\n",
       " ('httpaddr', [115, 38, 77, 39]),\n",
       " ('claim', [114, 0, 114, 114]),\n",
       " ('give', [114, 105, 9, -96])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictfreq = sortfreq[:100]\n",
    "len(dictfreq)\n",
    "dictfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\"knn\": KNeighborsClassifier(n_neighbors=1),\n",
    "\"naive_bayes\": GaussianNB(),\n",
    "\"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    "\"svm\": SVC(kernel=\"rbf\", gamma=\"auto\"),\n",
    "\"decision_tree\": DecisionTreeClassifier(),\n",
    "\"random_forest\": RandomForestClassifier(n_estimators=100),\n",
    "\"multi_nb\": MultinomialNB(),\n",
    " \"mlp\": MLPClassifier(),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.msg\n",
    "y=df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= CountVectorizer()\n",
    "counts = vectorizer.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "targets =y_train.values\n",
    "classifier.fit(counts,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'multi_nb' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name=\"multi_nb\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'knn' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name=\"knn\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'mlp' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"mlp\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'logit' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"logit\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'svm' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"svm\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'random_forest' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"random_forest\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'decision_tree' model\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      1212\n",
      "        spam       0.98      0.98      0.98       181\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1393\n",
      "   macro avg       0.99      0.99      0.99      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name=\"decision_tree\"\n",
    "model = models[model_name]\n",
    "model.fit(counts,targets)\n",
    "exp_count=vectorizer.transform(X_test)\n",
    "predictions= classifier.predict(exp_count)\n",
    "print(\"[INFO] using '{}' model\".format(model_name))\n",
    "print(\"[INFO] evaluating...\")\n",
    "#predictions = model.predict(testX)\n",
    "\n",
    "print(classification_report(y_test, predictions,\n",
    "target_names=['ham','spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go jurong point crazi avail bugi n great world...\n",
       "1                                   ok lar joke wif u oni\n",
       "2       free entri numbr wkli comp win fa cup final tk...\n",
       "3                     u dun say earli hor u c alreadi say\n",
       "4                  nah i think goe usf live around though\n",
       "5       freemsg hey darl numbr week s word back i d li...\n",
       "6       even brother like speak me they treat like aid...\n",
       "7       as per request mell mell oru minnaminungint nu...\n",
       "8       winner as valu network custom select receivea ...\n",
       "9       had mobil numbr month more u r entitl updat la...\n",
       "10      i m gonna home soon want talk stuff anymor ton...\n",
       "11      six chanc win cash from numbr numbr numbr poun...\n",
       "12      urgent you numbr week free membership numbr nu...\n",
       "13      i ve search right word thank breather i promis...\n",
       "14                      i have a date on sunday with will\n",
       "15      xxxmobilemovieclub to use credit click wap lin...\n",
       "16                                    oh k i m watch here\n",
       "17      eh u rememb numbr spell name ye did he v naugh...\n",
       "18               fine that s way u feel that s way gota b\n",
       "19      england v macedonia dont miss goal team news t...\n",
       "20                                  is serious spell name\n",
       "21                      i m go tri numbr month ha ha joke\n",
       "22                 so Ã¼ pay first lar then da stock comin\n",
       "23      aft finish lunch go str lor ard numbr smth lor...\n",
       "24                   ffffffffff alright way i meet sooner\n",
       "25      just forc eat slice i m realli hungri tho thi ...\n",
       "26                                      lol alway convinc\n",
       "27      did catch bu are fri egg did make tea are eat ...\n",
       "28      i m back amp we re pack car now i ll let know ...\n",
       "29        ahhh work i vagu rememb that what feel like lol\n",
       "                              ...                        \n",
       "5542                           armand say get ass epsilon\n",
       "5543                  u still havent got urself jacket ah\n",
       "5544    i m take derek amp taylor walmart i m back tim...\n",
       "5545                               hi durban still number\n",
       "5546                    ic there lotta childporn car then\n",
       "5547    had contract mobil numbr mnth latest motorola ...\n",
       "5548                                   no i tri weekend v\n",
       "5549    you know wot peopl wear t shirt jumper hat bel...\n",
       "5550                             cool time think get here\n",
       "5551                    wen get spiritu deep that s great\n",
       "5552    have safe trip nigeria wish happi soon compani...\n",
       "5553                                hahaha use brain dear\n",
       "5554    well keep mind i ve got enough ga one round tr...\n",
       "5555    yeh indian nice tho kane bit he we shud go num...\n",
       "5556             ye have so that s u text pshew miss much\n",
       "5557    no i meant calcul same that lt gt unit lt gt t...\n",
       "5558                                sorri i ll call later\n",
       "5559                       next lt gt hour imma flip shit\n",
       "5560                                 anyth lor juz us lor\n",
       "5561             get dump heap my mom decid come low bore\n",
       "5562    ok lor soni ericsson salesman i ask shuhui say...\n",
       "5563                               ard numbr like dat lor\n",
       "5564                 whi wait til least wednesday see get\n",
       "5565                                              huh lei\n",
       "5566    remind from onumbr to get numbr pound free cal...\n",
       "5567    thi numbrnd time tri numbr contact u u numbr p...\n",
       "5568                         will Ã¼ b go esplanad fr home\n",
       "5569                        piti mood that so ani suggest\n",
       "5570    the guy bitch i act like i d interest buy some...\n",
       "5571                                    rofl it true name\n",
       "Name: msg, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 msg class\n",
       "0  go jurong point crazi avail bugi n great world...     0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0'], dtype='<U1')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2=vectorizer.transform(exp)\n",
    "classifier.predict(exp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
